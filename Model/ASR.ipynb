{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e1773634-d315-4da3-984e-871fef1d072d",
    "_uuid": "e5333bf8-deb6-4de7-80ba-9cf255b17b63",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-13T21:57:03.903266Z",
     "iopub.status.busy": "2025-06-13T21:57:03.902869Z",
     "iopub.status.idle": "2025-06-13T21:57:05.219562Z",
     "shell.execute_reply": "2025-06-13T21:57:05.218232Z",
     "shell.execute_reply.started": "2025-06-13T21:57:03.903226Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/audio2/you-need-to-move-faster-vocal-spoken-shot_70bpm_E_minor.wav\n",
      "/kaggle/input/fork-of-asrdataprocessing/__results__.html\n",
      "/kaggle/input/fork-of-asrdataprocessing/__huggingface_repos__.json\n",
      "/kaggle/input/fork-of-asrdataprocessing/train_data.csv\n",
      "/kaggle/input/fork-of-asrdataprocessing/test_data.csv\n",
      "/kaggle/input/fork-of-asrdataprocessing/__notebook__.ipynb\n",
      "/kaggle/input/fork-of-asrdataprocessing/__output__.json\n",
      "/kaggle/input/fork-of-asrdataprocessing/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:57:44.652416Z",
     "iopub.status.busy": "2025-06-13T21:57:44.652020Z",
     "iopub.status.idle": "2025-06-13T21:57:45.143985Z",
     "shell.execute_reply": "2025-06-13T21:57:45.142663Z",
     "shell.execute_reply.started": "2025-06-13T21:57:44.652384Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486210696ee24871b59e4f3783e230dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:57:50.815210Z",
     "iopub.status.busy": "2025-06-13T21:57:50.814740Z",
     "iopub.status.idle": "2025-06-13T21:58:02.582388Z",
     "shell.execute_reply": "2025-06-13T21:58:02.581228Z",
     "shell.execute_reply.started": "2025-06-13T21:57:50.815169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a32395c74e468c844ce126ae5b990e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6208e4f293da4b8d9de7d448ab1cb838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bf7ed3defd426ab838d0e96e1630be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39200ba86c104c6e833cbc832aaf82d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9492f08fc8234e8297d1abcf37082c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1851815cf7c408588e547409bc9b67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec8aa92bca24ce9879447c0eefe8a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cbedd1ac9e424ca9c3c2c1b5963feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:58:13.149138Z",
     "iopub.status.busy": "2025-06-13T21:58:13.148781Z",
     "iopub.status.idle": "2025-06-13T21:58:13.906854Z",
     "shell.execute_reply": "2025-06-13T21:58:13.905628Z",
     "shell.execute_reply.started": "2025-06-13T21:58:13.149109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:58:15.046166Z",
     "iopub.status.busy": "2025-06-13T21:58:15.045808Z",
     "iopub.status.idle": "2025-06-13T22:00:43.407883Z",
     "shell.execute_reply": "2025-06-13T22:00:43.406317Z",
     "shell.execute_reply.started": "2025-06-13T21:58:15.046140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca7234c842a403db957174cf2a8fe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/920 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e409c82b6b1e4743958b352b6aa77f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55714bef99b4295a8515f93f822aa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/28 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40e5401659f4a6da51a12d98960ffc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00028.parquet:   0%|          | 0.00/519M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876cb351589a440596019ae975624cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00028.parquet:   0%|          | 0.00/514M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020e3b6f22804ae89663824a910b53c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00028.parquet:   0%|          | 0.00/389M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0aa68fe9c840c98f09a4c3062ffc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00028.parquet:   0%|          | 0.00/187M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004892855fb24ad199dfebbf49e1757c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00028.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac6a27d7ec342e0b7da7396cb87c201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00028.parquet:   0%|          | 0.00/197M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145c1f136c9f4e8fa133e404eea39149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00028.parquet:   0%|          | 0.00/208M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c35b6ad92c04a1aaf87cd57704260f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00028.parquet:   0%|          | 0.00/197M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477ab1a1bd8f443ea36638e02c9b6205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00028.parquet:   0%|          | 0.00/203M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b401b84f7c494e969c429eed3392bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00028.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d321b01fea441b9aed650bb61bbd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00028.parquet:   0%|          | 0.00/203M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0521a6dde04b949104222c79cb5805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00028.parquet:   0%|          | 0.00/194M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d38c98a1de949b09d0331849170e4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00028.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6113e1ce53a41a5950a6f82ee0e81bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00028.parquet:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a978954a411418ea96eeeb13e45f8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00028.parquet:   0%|          | 0.00/175M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13711684b9604bcaaa20228555d7f2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00028.parquet:   0%|          | 0.00/200M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdf2fa3c43647f7b975a635349b3c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00016-of-00028.parquet:   0%|          | 0.00/217M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0241d26397142958ddc8bb4badd7234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00017-of-00028.parquet:   0%|          | 0.00/235M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bce1e9d85444587860474fa0e479e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00018-of-00028.parquet:   0%|          | 0.00/236M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14362ac3a71443a80948204fa3457d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00019-of-00028.parquet:   0%|          | 0.00/194M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8bbfc0a3124dfda9137726dc670ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00020-of-00028.parquet:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a6a6a2ec848859458de825ec90e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00021-of-00028.parquet:   0%|          | 0.00/183M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ca3884bf374a0d9f83590599391a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00022-of-00028.parquet:   0%|          | 0.00/177M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbf9fa0978c44ea9a8c98e49799e96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00023-of-00028.parquet:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9d600528114f0c96a1b544e7b4625a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00024-of-00028.parquet:   0%|          | 0.00/650M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947d4c6c343040749e4cf4b9c80499fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00025-of-00028.parquet:   0%|          | 0.00/646M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2332b1953484071a32659cfc7c9c35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00026-of-00028.parquet:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490e2996b8254b73aee66293a65d149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00027-of-00028.parquet:   0%|          | 0.00/644M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8d7043ab514786bee05b095e964dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/169M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf05842d4ff43b192acf167c7c21eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/280M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a730bdad4fa845838bb579ee8f2283b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885f13eeba940beb0e2b6a1e82910e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afabe96b4cc4b1096ad41a86d440ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69fad0756c04dad81e290d44acf6c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "Data = load_dataset(\"westbrook/English_Accent_DataSet\",trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:28:01.859515Z",
     "iopub.status.busy": "2025-06-13T18:28:01.858684Z",
     "iopub.status.idle": "2025-06-13T18:28:01.865233Z",
     "shell.execute_reply": "2025-06-13T18:28:01.864296Z",
     "shell.execute_reply.started": "2025-06-13T18:28:01.859483Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio_id', 'audio', 'raw_text', 'gender', 'speaker_id', 'duration', 'accent', 'split'],\n",
       "        num_rows: 50382\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['audio_id', 'audio', 'raw_text', 'gender', 'speaker_id', 'duration', 'accent', 'split'],\n",
       "        num_rows: 1036\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio_id', 'audio', 'raw_text', 'gender', 'speaker_id', 'duration', 'accent', 'split'],\n",
       "        num_rows: 1620\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:43.411591Z",
     "iopub.status.busy": "2025-06-13T22:00:43.409896Z",
     "iopub.status.idle": "2025-06-13T22:00:43.416744Z",
     "shell.execute_reply": "2025-06-13T22:00:43.415838Z",
     "shell.execute_reply.started": "2025-06-13T22:00:43.411545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Train_Data=Data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:43.419209Z",
     "iopub.status.busy": "2025-06-13T22:00:43.418825Z",
     "iopub.status.idle": "2025-06-13T22:00:45.334835Z",
     "shell.execute_reply": "2025-06-13T22:00:45.333460Z",
     "shell.execute_reply.started": "2025-06-13T22:00:43.419176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vali_data=Data[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:45.337658Z",
     "iopub.status.busy": "2025-06-13T22:00:45.337150Z",
     "iopub.status.idle": "2025-06-13T22:00:46.363973Z",
     "shell.execute_reply": "2025-06-13T22:00:46.362344Z",
     "shell.execute_reply.started": "2025-06-13T22:00:45.337610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Test_data=Data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:28:17.736210Z",
     "iopub.status.busy": "2025-06-13T18:28:17.735928Z",
     "iopub.status.idle": "2025-06-13T18:28:17.809268Z",
     "shell.execute_reply": "2025-06-13T18:28:17.808596Z",
     "shell.execute_reply.started": "2025-06-13T18:28:17.736188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:                 OKAY NOW FOR A REGULAR CONVERSATION SO UH WOULD YOU RATHER GO TO THE BEACH TODAY OR DO CLUB GOLF DISCUSS\n",
      "Decoded w/ special:    <|startoftranscript|><|notimestamps|>OKAY NOW FOR A REGULAR CONVERSATION SO UH WOULD YOU RATHER GO TO THE BEACH TODAY OR DO CLUB GOLF DISCUSS<|endoftext|>\n",
      "Decoded w/out special: OKAY NOW FOR A REGULAR CONVERSATION SO UH WOULD YOU RATHER GO TO THE BEACH TODAY OR DO CLUB GOLF DISCUSS\n",
      "Are equal:             True\n"
     ]
    }
   ],
   "source": [
    "input_str = Data[\"train\"][\"raw_text\"][0]\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T19:46:35.039573Z",
     "iopub.status.busy": "2025-06-13T19:46:35.039202Z",
     "iopub.status.idle": "2025-06-13T19:46:35.044820Z",
     "shell.execute_reply": "2025-06-13T19:46:35.043873Z",
     "shell.execute_reply.started": "2025-06-13T19:46:35.039543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # Compute log-Mel input features\n",
    "    batch[\"input_features\"] = feature_extractor(\n",
    "        audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]\n",
    "    ).input_features[0]\n",
    "\n",
    "    encoded = tokenizer(\n",
    "        [batch[\"raw_text\"]],  \n",
    "        padding=\"longest\",  \n",
    "        truncation=True,\n",
    "        max_length=448,  \n",
    "        return_tensors=\"pt\"  \n",
    "    )\n",
    "\n",
    "    input_ids = encoded.input_ids[0].tolist()\n",
    "\n",
    "    batch[\"decoder_input_ids\"] = input_ids\n",
    "\n",
    "    batch[\"labels\"] = [-100] + input_ids[:-1]\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:46.365980Z",
     "iopub.status.busy": "2025-06-13T22:00:46.365478Z",
     "iopub.status.idle": "2025-06-13T22:00:47.189279Z",
     "shell.execute_reply": "2025-06-13T22:00:47.187866Z",
     "shell.execute_reply.started": "2025-06-13T22:00:46.365931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    inputs = feature_extractor(\n",
    "        audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    batch[\"input_features\"] = inputs.input_features.squeeze(0)\n",
    "\n",
    "    labels = processor.tokenizer(\n",
    "        batch[\"raw_text\"],\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    batch[\"labels\"] = labels.squeeze(0)\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:47.190578Z",
     "iopub.status.busy": "2025-06-13T22:00:47.190264Z",
     "iopub.status.idle": "2025-06-13T22:00:48.326278Z",
     "shell.execute_reply": "2025-06-13T22:00:48.325032Z",
     "shell.execute_reply.started": "2025-06-13T22:00:47.190550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Train_Data = Train_Data.remove_columns([\"audio_id\", \"gender\", \"speaker_id\", \"duration\",\"split\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:48.328520Z",
     "iopub.status.busy": "2025-06-13T22:00:48.328116Z",
     "iopub.status.idle": "2025-06-13T22:00:49.125820Z",
     "shell.execute_reply": "2025-06-13T22:00:49.124454Z",
     "shell.execute_reply.started": "2025-06-13T22:00:48.328480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vali_data=vali_data.remove_columns([\"audio_id\", \"gender\", \"speaker_id\", \"duration\",\"split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:49.129652Z",
     "iopub.status.busy": "2025-06-13T22:00:49.129228Z",
     "iopub.status.idle": "2025-06-13T22:00:50.003467Z",
     "shell.execute_reply": "2025-06-13T22:00:50.001800Z",
     "shell.execute_reply.started": "2025-06-13T22:00:49.129625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Test_data= Test_data.remove_columns([\"audio_id\", \"gender\", \"speaker_id\", \"duration\",\"split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:28:54.992216Z",
     "iopub.status.busy": "2025-06-13T21:28:54.991917Z",
     "iopub.status.idle": "2025-06-13T21:28:54.997239Z",
     "shell.execute_reply": "2025-06-13T21:28:54.996259Z",
     "shell.execute_reply.started": "2025-06-13T21:28:54.992193Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'raw_text', 'accent'],\n",
       "    num_rows: 50382\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:00:50.005402Z",
     "iopub.status.busy": "2025-06-13T22:00:50.004995Z",
     "iopub.status.idle": "2025-06-13T22:19:07.905555Z",
     "shell.execute_reply": "2025-06-13T22:19:07.903138Z",
     "shell.execute_reply.started": "2025-06-13T22:00:50.005363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fab38a911ac4c6c9ef9a08bcacb79f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2729 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "Train_Data = Train_Data.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=[\"audio\", \"raw_text\", \"accent\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:19:07.914183Z",
     "iopub.status.busy": "2025-06-13T22:19:07.912604Z",
     "iopub.status.idle": "2025-06-13T22:19:31.545338Z",
     "shell.execute_reply": "2025-06-13T22:19:31.543880Z",
     "shell.execute_reply.started": "2025-06-13T22:19:07.914110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e7ea04858b4d5593c1375e7e950866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Eval_Data = vali_data.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=[\"audio\", \"raw_text\", \"accent\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T01:38:24.312184Z",
     "iopub.status.busy": "2025-05-20T01:38:24.311813Z",
     "iopub.status.idle": "2025-05-20T01:38:24.321672Z",
     "shell.execute_reply": "2025-05-20T01:38:24.320472Z",
     "shell.execute_reply.started": "2025-05-20T01:38:24.312156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Test_Data = Test_Data.remove_columns([\"id\", \"begin_time\", \"end_time\", \"microphone_id\", \"speaker_id\",\"meeting_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:11:34.379746Z",
     "iopub.status.busy": "2025-06-13T21:11:34.379360Z",
     "iopub.status.idle": "2025-06-13T21:11:34.385186Z",
     "shell.execute_reply": "2025-06-13T21:11:34.384561Z",
     "shell.execute_reply.started": "2025-06-13T21:11:34.379714Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_features', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
       "    num_rows: 50382\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:47:43.714197Z",
     "iopub.status.busy": "2025-06-13T21:47:43.713878Z",
     "iopub.status.idle": "2025-06-13T21:47:44.042212Z",
     "shell.execute_reply": "2025-06-13T21:47:44.041455Z",
     "shell.execute_reply.started": "2025-06-13T21:47:43.714173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 shape: [[-2.47472644e-01 -2.53605843e-03 -4.33615446e-02 ... -5.66902876e-01\n",
      "  -5.66902876e-01 -5.66902876e-01]\n",
      " [ 2.36332417e-04  8.39462280e-02  1.63371980e-01 ... -5.66902876e-01\n",
      "  -5.66902876e-01 -5.66902876e-01]\n",
      " [-4.64433432e-02  3.78401279e-01  3.60894144e-01 ... -5.66902876e-01\n",
      "  -5.66902876e-01 -5.66902876e-01]\n",
      " ...\n",
      " [-3.74663115e-01 -5.66902876e-01 -5.66902876e-01 ... -5.66902876e-01\n",
      "  -5.66902876e-01 -5.66902876e-01]\n",
      " [-3.77551675e-01 -5.66902876e-01 -5.66902876e-01 ... -5.66902876e-01\n",
      "  -5.66902876e-01 -5.66902876e-01]\n",
      " [-2.60195494e-01 -5.66902876e-01 -5.66902876e-01 ... -5.66902876e-01\n",
      "  -5.66902876e-01 -5.66902876e-01]]\n",
      "Sample 1 shape: [[-0.36688423 -0.2894913  -0.31850016 ... -0.68437302 -0.68437302\n",
      "  -0.68437302]\n",
      " [-0.56619132 -0.53301644 -0.34276819 ... -0.68437302 -0.68437302\n",
      "  -0.68437302]\n",
      " [-0.41276681 -0.35889447 -0.31223428 ... -0.68437302 -0.68437302\n",
      "  -0.68437302]\n",
      " ...\n",
      " [-0.68437302 -0.68437302 -0.68437302 ... -0.68437302 -0.68437302\n",
      "  -0.68437302]\n",
      " [-0.68437302 -0.68437302 -0.68437302 ... -0.68437302 -0.68437302\n",
      "  -0.68437302]\n",
      " [-0.68437302 -0.68437302 -0.68437302 ... -0.68437302 -0.68437302\n",
      "  -0.68437302]]\n",
      "Sample 2 shape: [[ 0.76741344  0.05237675  0.10660362 ... -0.61679983 -0.61679983\n",
      "  -0.61679983]\n",
      " [ 0.79129094  0.41799325  0.3786484  ... -0.61679983 -0.61679983\n",
      "  -0.61679983]\n",
      " [ 0.84338415  0.35623074  0.36089134 ... -0.61679983 -0.61679983\n",
      "  -0.61679983]\n",
      " ...\n",
      " [ 0.42303985  0.25654155  0.09481394 ... -0.61679983 -0.61679983\n",
      "  -0.61679983]\n",
      " [ 0.0486052   0.11642832  0.02717698 ... -0.61679983 -0.61679983\n",
      "  -0.61679983]\n",
      " [ 0.14523691 -0.23885047 -0.54908967 ... -0.61679983 -0.61679983\n",
      "  -0.61679983]]\n"
     ]
    }
   ],
   "source": [
    "# better view of some samples\n",
    "for i in range(3):\n",
    "    arr = np.array(Eval_Data[i][\"input_features\"])\n",
    "    print(f\"Sample {i} shape: {arr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:19:31.547555Z",
     "iopub.status.busy": "2025-06-13T22:19:31.547223Z",
     "iopub.status.idle": "2025-06-13T22:19:50.021210Z",
     "shell.execute_reply": "2025-06-13T22:19:50.019679Z",
     "shell.execute_reply.started": "2025-06-13T22:19:31.547525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef921dfb0ba14e4dadb3a45cdff6ddff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44383d5d78084a8d946031d786fb8521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5d951d1847436dac4792be0f14bd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "model_name = \"openai/whisper-medium\"  \n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "3d1c2625-c8aa-4951-9705-1f1e68f2b109",
    "_uuid": "730161bc-a40b-46f7-8149-f26073fb6258",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-13T22:20:15.960177Z",
     "iopub.status.busy": "2025-06-13T22:20:15.959071Z",
     "iopub.status.idle": "2025-06-13T22:20:15.975274Z",
     "shell.execute_reply": "2025-06-13T22:20:15.970564Z",
     "shell.execute_reply.started": "2025-06-13T22:20:15.960124Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:23:40.521961Z",
     "iopub.status.busy": "2025-06-13T22:23:40.521572Z",
     "iopub.status.idle": "2025-06-13T22:23:40.532187Z",
     "shell.execute_reply": "2025-06-13T22:23:40.530905Z",
     "shell.execute_reply.started": "2025-06-13T22:23:40.521933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            [{\"input_features\": f[\"input_features\"]} for f in features],\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            [{\"input_ids\": f[\"labels\"]} for f in features],\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        decoder_input_ids = torch.cat(\n",
    "            [\n",
    "                torch.full((labels.shape[0], 1), self.decoder_start_token_id, dtype=labels.dtype),\n",
    "                labels.clone()\n",
    "            ],\n",
    "            dim=1\n",
    "        )\n",
    "        batch[\"decoder_input_ids\"] = decoder_input_ids\n",
    "        batch[\"decoder_attention_mask\"] = (decoder_input_ids != -100).long()\n",
    "\n",
    "        return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "663571b4-ab4e-4e4d-9996-028030ab8494",
    "_uuid": "3b048f51-a6c7-4fdd-a0e1-b234c1e476f7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-13T22:23:43.012440Z",
     "iopub.status.busy": "2025-06-13T22:23:43.012060Z",
     "iopub.status.idle": "2025-06-13T22:23:43.017588Z",
     "shell.execute_reply": "2025-06-13T22:23:43.016095Z",
     "shell.execute_reply.started": "2025-06-13T22:23:43.012412Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:23:46.253754Z",
     "iopub.status.busy": "2025-06-13T22:23:46.253326Z",
     "iopub.status.idle": "2025-06-13T22:23:57.085597Z",
     "shell.execute_reply": "2025-06-13T22:23:57.083887Z",
     "shell.execute_reply.started": "2025-06-13T22:23:46.253722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, click, jiwer, evaluate\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "Successfully installed click-8.2.1 evaluate-0.4.3 jiwer-3.1.0 rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "46c2e871-3b8c-48ab-8449-a7f9c7f32f6a",
    "_uuid": "1d582775-eeb5-47de-a413-58ea62b94cb7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-13T22:23:57.088283Z",
     "iopub.status.busy": "2025-06-13T22:23:57.087836Z",
     "iopub.status.idle": "2025-06-13T22:23:57.679290Z",
     "shell.execute_reply": "2025-06-13T22:23:57.677961Z",
     "shell.execute_reply.started": "2025-06-13T22:23:57.088239Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3183d1b441ac478c8c5fa3894e902f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:23:57.681995Z",
     "iopub.status.busy": "2025-06-13T22:23:57.681591Z",
     "iopub.status.idle": "2025-06-13T22:23:57.688435Z",
     "shell.execute_reply": "2025-06-13T22:23:57.687146Z",
     "shell.execute_reply.started": "2025-06-13T22:23:57.681964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:23:58.268577Z",
     "iopub.status.busy": "2025-06-13T22:23:58.268222Z",
     "iopub.status.idle": "2025-06-13T22:23:58.273644Z",
     "shell.execute_reply": "2025-06-13T22:23:58.272336Z",
     "shell.execute_reply.started": "2025-06-13T22:23:58.268549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:24:00.853373Z",
     "iopub.status.busy": "2025-06-13T22:24:00.852909Z",
     "iopub.status.idle": "2025-06-13T22:24:05.822124Z",
     "shell.execute_reply": "2025-06-13T22:24:05.820333Z",
     "shell.execute_reply.started": "2025-06-13T22:24:00.853337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install  peft  accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:24:05.824630Z",
     "iopub.status.busy": "2025-06-13T22:24:05.824206Z",
     "iopub.status.idle": "2025-06-13T22:24:07.105324Z",
     "shell.execute_reply": "2025-06-13T22:24:07.103976Z",
     "shell.execute_reply.started": "2025-06-13T22:24:05.824593Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 17,301,504 (~17.30M)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): WhisperForConditionalGeneration(\n",
       "      (model): WhisperModel(\n",
       "        (encoder): WhisperEncoder(\n",
       "          (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (embed_positions): Embedding(1500, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x WhisperEncoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (fc2): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): WhisperDecoder(\n",
       "          (embed_tokens): Embedding(51865, 1024, padding_idx=50257)\n",
       "          (embed_positions): WhisperPositionalEmbedding(448, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x WhisperDecoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): WhisperSdpaAttention(\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (fc2): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1024, out_features=51865, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "# Freeze layers (e.g., encoder and all but the last few decoder layers)\n",
    "for param in model.model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for layer in model.model.decoder.layers[:-2]:  # Unfreeze last 2 decoder layers\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Apply LoRA to specific layers (e.g., attention and feed-forward in unfrozen decoder layers)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank of LoRA adapters (low rank for efficiency)\n",
    "    lora_alpha=32,  # Scaling factor for adapters\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\", \"fc1\", \"fc2\"],  # Whisper attention and FFN layers\n",
    "    lora_dropout=0.1,  \n",
    "    bias=\"none\",  \n",
    "    task_type=\"CAUSAL_LM\"  \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {total_params:,} (~{total_params / 1e6:.2f}M)\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de5d7a64-350d-4f5e-a8a1-5352488594a6",
    "_uuid": "676038f9-ffea-4e6e-9324-856b673ee9ff",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-13T22:24:25.247779Z",
     "iopub.status.busy": "2025-06-13T22:24:25.247306Z",
     "iopub.status.idle": "2025-06-13T22:24:25.254868Z",
     "shell.execute_reply": "2025-06-13T22:24:25.253369Z",
     "shell.execute_reply.started": "2025-06-13T22:24:25.247733Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-medium-hi32\", \n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,  \n",
    "    learning_rate=5e-4,\n",
    "    warmup_steps=500,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"none\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T22:26:12.164220Z",
     "iopub.status.busy": "2025-06-13T22:26:12.163241Z",
     "iopub.status.idle": "2025-06-13T22:26:12.174330Z",
     "shell.execute_reply": "2025-06-13T22:26:12.172992Z",
     "shell.execute_reply.started": "2025-06-13T22:26:12.164176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "class WhisperTrainer(Seq2SeqTrainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        inputs = {\n",
    "            \"input_features\": inputs[\"input_features\"],\n",
    "            \"labels\": inputs[\"labels\"]\n",
    "        }\n",
    "        if \"decoder_input_ids\" in inputs:\n",
    "            inputs[\"decoder_input_ids\"] = inputs[\"decoder_input_ids\"]\n",
    "        if \"decoder_attention_mask\" in inputs:\n",
    "            inputs[\"decoder_attention_mask\"] = inputs[\"decoder_attention_mask\"]\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "f9e9b96c-13fd-4c67-ba8e-f2fdd1308e13",
    "_uuid": "12651aea-9923-4742-83f0-720057cdfad2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-13T22:26:53.053280Z",
     "iopub.status.busy": "2025-06-13T22:26:53.052889Z",
     "iopub.status.idle": "2025-06-13T22:26:53.165567Z",
     "shell.execute_reply": "2025-06-13T22:26:53.164416Z",
     "shell.execute_reply.started": "2025-06-13T22:26:53.053253Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = WhisperTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=Train_Data,\n",
    "    eval_dataset=Eval_Data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=processor.feature_extractor,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T22:26:55.260943Z",
     "iopub.status.busy": "2025-06-13T22:26:55.260540Z",
     "iopub.status.idle": "2025-06-13T22:27:01.184772Z",
     "shell.execute_reply": "2025-06-13T22:27:01.182888Z",
     "shell.execute_reply.started": "2025-06-13T22:26:55.260911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WhisperTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2153\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   2156\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2520\u001b[0m                     )\n\u001b[1;32m   2521\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m                     if (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3653\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: WhisperTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T14:15:13.408584Z",
     "iopub.status.busy": "2025-04-14T14:15:13.408253Z",
     "iopub.status.idle": "2025-04-14T14:15:13.931613Z",
     "shell.execute_reply": "2025-04-14T14:15:13.930785Z",
     "shell.execute_reply.started": "2025-04-14T14:15:13.408562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”® Model Prediction:  if you if you ask an agent they have this big warning about doing nothing at all and negate their machine.\n"
     ]
    }
   ],
   "source": [
    "# Replace with any audio sample from your dataset\n",
    "sample_audio = Train_Data[0][\"input_features\"]\n",
    "\n",
    "input_features = processor.feature_extractor.pad(\n",
    "    {\"input_features\": [sample_audio]},\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_features[\"input_features\"].to(model.device),\n",
    "    max_length=448\n",
    ")\n",
    "\n",
    "prediction = processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(\"ðŸ”® Model Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T14:12:57.801309Z",
     "iopub.status.busy": "2025-04-14T14:12:57.801014Z",
     "iopub.status.idle": "2025-04-14T14:12:57.815855Z",
     "shell.execute_reply": "2025-04-14T14:12:57.815029Z",
     "shell.execute_reply.started": "2025-04-14T14:12:57.801283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_features', 'decoder_input_ids', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(sample.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-14T03:41:18.100684Z",
     "iopub.status.idle": "2025-04-14T03:41:18.100940Z",
     "shell.execute_reply": "2025-04-14T03:41:18.100836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./last_checkpoint\")  # Save model\n",
    "trainer.state.save_to_json(\"./last_checkpoint/trainer_state.json\")  # Save training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T12:05:17.847236Z",
     "iopub.status.busy": "2025-03-28T12:05:17.846927Z",
     "iopub.status.idle": "2025-03-28T12:05:23.617713Z",
     "shell.execute_reply": "2025-03-28T12:05:23.617053Z",
     "shell.execute_reply.started": "2025-03-28T12:05:17.847214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Saving progress before session ends\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Load a test audio file\n",
    "speech_array, sampling_rate = torchaudio.load(\"/kaggle/input/audio2/you-need-to-move-faster-vocal-spoken-shot_70bpm_E_minor.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert audio to 16kHz if needed\n",
    "speech_array = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)(speech_array)\n",
    "\n",
    "# Process input features\n",
    "input_features = processor(speech_array.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate prediction\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(input_features)\n",
    "\n",
    "# Decode the predicted text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"Predicted Text:\", transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6878578,
     "sourceId": 11042549,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 227335980,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 227982799,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
